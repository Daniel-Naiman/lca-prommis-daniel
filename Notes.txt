This document includes the development notes of the PrOMMiS LCA Integration code

The flow includes 5 main tasks:
1- Extract inputs/outputs from PrOMMiS 
2- Communicate PrOMMiS resuts with openLCA
3- Run openLCA model 
4- Extract openLCA results
5- Pass openLCA results to PrOMMiS

Step 1: Extract inputs/outputs from PrOMMiS
--------------------------------------------
This step is performed entirely in prommis_LCA_data.py

    Step 1.1: Identify all LCA-relevant flows in the UKy PrOMMiS flowsheet
    ======================================================================
In total, 17 material streams with 45 material flows were identified in addition to 4 electricity flows and 2 heat flows. 2 new flows were also added to reflect data from the NETL UP Library: sodium hydroxide and oxalic acid.

    Step 1.2: Extract all flows/parameters and structure them in a dataframe 
    =========================================================================

The end goal of this step is to have all relevant flows structured as follow:

| Flow_ID | Flow        | In/Out |   Category   | Amount 1 | Unit 1 | Amount 2 | Unit 2 | 
|---------|-------------|--------|--------------|----------|--------|----------|--------|
|    1    | Pump power  |   In   |  Electricity |  12      | kW     |          |        |
|    2    | Li product  |   Out  |  Product     |  136     | kg/hr  |          |        |
|    3    | Feed - MatX |   In   |  Material    |  100     | m3/hr  |  1.7     | kg/m3  |

This structure is passed into a csv file using prommis_LCA_data.py, which runs the UKy flowsheet and extracts the relevant LCA data.


Step 2: Communicate PrOMMiS results with openLCA
------------------------------------------------

    Step 2.1: Develop function to convert PrOMMiS results to LCA-relevant results
    ============================================================================
This step is performed in prommis_LCA_conversions.py. The main function in the script, convert_flows_to_lca_units, 
adds two new columns to the dataframe from step 1: LCA Amount and LCA Unit (usually kg, m3, L, kWh, or MJ). This 
function uses the Pyomo framework and a robust error-handling system to convert any common unit to LCA units. 
It also uses pubchempy and pymatgen to convert moles to kg for any common chemical name. 
It returns the new df and creates a new csv file.

    Step 2.2: Develop function that evaluates PrOMMiS flows and converts them to LCA-relevant flows normalized to selected FU.
    =========================================================================================================================
This step is performed in finalize_LCA_flows.py. The main() function utilizes the merge_flows and finalize_df functions to convert 
the LCA information into a new dataframe which is ready to be imported into openLCA. The main function completes the following steps:

1. Imports the LCA csv from the previous step
2. Uses the merge_flows function to:
    a. Combine the REO feed streams into one single feed stream, "374 ppm REO Feed"
    b. Combine the REO product streams into one single product stream, "99.85% REO Product"
3. Enters the dataframe and the desired reference flow into the finalize_df function to:
    a. Convert all LCA values based on the functional unit/reference flow using the convert_to_functional_unit function
    b. Create a new dataframe with only 7 columns: Flow_Name, LCA_Amount, LCA_Unit, Is_Input, Reference_Product, Flow_Type, and Description
    c. Combine identical flows into one value using the merge_duplicate_flows function
4. Returns this new dataframe and creates a new csv file

    Step 2.3: Pass converted PrOMMiS outputs to openLCA 
    ===================================================

    The code in this step involves several steps that mimic the process creation in openLCA
    1- Use olca ipc to connect to openLCA
    2- Create a new unit process and prompt the user to enter its metadata (e.g., name, description, etc.)
    3- Read the dataframe produced in steps 2.1 and 2.2
    4- A function loops through the dataframe row by row and for each row creates a flow to be entered in the unit process
            - The function first creates an empty process
            - then it creates an exchange for the reference product
            - then for each row in the given dataframe
                - if the flow is ELEMENTARY_FLOW --> the function automatically creates an exchange for it using a predefined uuid
                    * Our work includes a dictionary for elementary flows in FEDEFL with their uuids
                - if the flow is product or waste flow 
                    * the user enters a keyword used to fetch given flows
                    * the user selects a flow from a given convert_flows_to_lca_units
                    * the function searches for processes that provide the given flow
                    * the user select a process
                    * FUNCTION MOVES TO THE NEXT ROW 
        For all the steps above, the flow amount, unit, input/output are all retrieved from the given df generated in steps 2.1-2.2
    
    #########################################################################
    # FOR FUTURE REFERENCE - TODO'S IN THE ABOVE STEPS
        High priority:
        --------------
        - Review the developed database
        - Compile inventory for missing chemicals in our database and create processes for them
        - Create a impact assessment method that calculates GWP, CED, and Water consumption - and add it to the database 
        
        Low priority:
        -------------
        - Provide the user with the option of changing their keyword 
        - Currently the function creates an exchange for that reference flow from scratch
            it should be modified to account for cases where a flow exists in the database for that reference product  

    #########################################################################

Step 3: Run openLCA model
-------------------------

Running the analysis in openLCA requires building the analysis setup
we should create a calculationsetup object and then define its attributes:
    - allocation --> if omitted then default allocation is used. In this version of the code, default allocation will be used.
    - amount: FU amount --> if omitted, the quantitative reference amount is used
    - impact_method --> if omitted, we don't get a LCIA but rather only a LCI
    - normalization and weighting set
    - parameters --> specific run parameter
    - target: this is what we're calculating --> this takes a product system object 
    - unit --> overrides FU
    - with_costs: includes cost calculation
    - with regionalization --> enables regionalized LCA

To run the analysis, the jupyter notebook user should use the run_analysis function which takes in three main arguments
    - the client (netl)
    - the product system uuid
    - the impact assessment method uuid

Here it's important to note that the method uuid will be pre-defined in the jupyter notebook.
In this project we are attaching a openLCA database that contains:
    - the needed libraries/processes to evaluate the PrOMMiS flowsheets
    - a impact assessment method that evaluates water consumption, CED, and global warming potential  

Step 4: Extract openLCA results
-------------------------------

Step 3 returns a result object that can be used to extract the LCIA results

In this step two sets of results are extracted for each impact category (GWP, CED, WC)
    - Total impact: The total impacts are calculated using the generate_total_results function in the generate_total_results.py module.
                    This function uses get_total_impacts() attribute of a olca_schema object 

    - Impacts by category:  This is also referred to as 'contribution tree' in openLCA. 
                            To get the contribution tree, we use the generate_contribution_tree function from the generate_contribution_tree.py module 
                            This method heavily relies on the utree module from olca_ipc library
                            This method requires the user to determine the number of nodes and levels.
                            Nodes are also referred to as the child nodes of a process like electricity, hear, sulfuric acid, etc. (e.g., impact by category)
                            Levels represent the number of step away from the main product.
                            Few important notes on this function and its application
                                a- setting nodes to (-1) reports all the nodes possible --> should be recommended in the analysis 
                                b- setting levels to (1) reports the total impact for each node (no ramifications)
                                c- the utree method in itself does not report direct contributions (e.g., direct emissions for GWP results)
                                    To resolve this, our function includes the necessary steps to back-calculate the direct contributions 
                                    using the total result and the table result for generate_contribution_tree(result, 1, -1)


Step 5: Pass openLCA results to PrOMMiS
---------------------------------------



Questions and future considerations
------------------------------------
1- Is hotspot analysis a part of the final outcome?
    If not then the current model structure is finalize_df
    If yes, then this would require modeling the UKy flowsheet (for example) 
    using process-based LCA rather than aggregating all the inventory in one unit process
    In the second case (yes), we might need to do minor changes to the model structure to 
    allow modeling each process unit separately (something to keep in mind: in the case of 
    processes producing co-products/by-products, this becomes exponentially more complex to 
    solve - but definitely doable)